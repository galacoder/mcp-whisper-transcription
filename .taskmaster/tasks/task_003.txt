# Task ID: 3
# Title: Create FastMCP server wrapper with initialization
# Status: pending
# Dependencies: 2
# Priority: high
# Description: Create the FastMCP server wrapper that integrates with existing WhisperTranscriber implementation
# Details:
Implement the main MCP server structure in src/whisper_mcp_server.py:

1. FastMCP Server Setup:
   ```python
   from fastmcp import FastMCP
   import os
   from pathlib import Path
   from dotenv import load_dotenv
   
   # Load environment variables
   load_dotenv()
   
   # Initialize FastMCP with metadata
   mcp = FastMCP(
       name="Whisper Transcription MCP",
       instructions="""
       This MCP server provides audio/video transcription using MLX-optimized Whisper models.
       Optimized for Apple Silicon devices with ultra-fast performance.
       
       Available tools:
       - transcribe_file: Transcribe a single file
       - batch_transcribe: Process multiple files
       - list_models: Show available Whisper models
       
       Supports multiple output formats: txt, md, srt, json
       """
   )
   ```

2. Import and Initialize Components:
   ```python
   import sys
   sys.path.append(str(Path(__file__).parent.parent))
   
   from transcribe_mlx import WhisperTranscriber
   from whisper_utils import (
       TranscriptionStats,
       PerformanceReport,
       OutputFormatter,
       setup_logger
   )
   
   # Global instances
   logger = setup_logger(Path("logs"), "WhisperMCP")
   transcriber = None  # Lazy initialization
   performance_report = PerformanceReport()
   ```

3. Configuration Management:
   ```python
   # Configuration from environment
   DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "mlx-community/whisper-large-v3-mlx")
   DEFAULT_FORMATS = os.getenv("OUTPUT_FORMATS", "txt,md,srt")
   MAX_WORKERS = int(os.getenv("MAX_WORKERS", "4"))
   TEMP_DIR = Path(os.getenv("TEMP_DIR", "./temp"))
   
   # Ensure directories exist
   TEMP_DIR.mkdir(exist_ok=True)
   Path("logs").mkdir(exist_ok=True)
   ```

4. Lazy Transcriber Initialization:
   ```python
   def get_transcriber(model_name: str = None) -> WhisperTranscriber:
       global transcriber
       model = model_name or DEFAULT_MODEL
       
       if transcriber is None or transcriber.model_name != model:
           logger.info(f"Initializing transcriber with model: {model}")
           transcriber = WhisperTranscriber(
               model_name=model,
               output_formats=DEFAULT_FORMATS
           )
       return transcriber
   ```

5. Error Handling Setup:
   ```python
   class TranscriptionError(Exception):
       """Custom exception for transcription errors"""
       pass
   
   # Add error handler middleware
   @mcp.error_handler
   async def handle_errors(error: Exception) -> dict:
       logger.error(f"MCP Error: {str(error)}", exc_info=True)
       return {
           "error": True,
           "message": str(error),
           "type": error.__class__.__name__
       }
   ```

6. Main Entry Point:
   ```python
   if __name__ == "__main__":
       # Check dependencies
       try:
           import mlx
           import ffmpeg
       except ImportError as e:
           logger.error(f"Missing dependency: {e}")
           print(f"Error: {e}")
           print("Please install all dependencies: poetry install")
           sys.exit(1)
       
       # Run the server
       logger.info("Starting Whisper Transcription MCP Server")
       mcp.run()
   ```

# Test Strategy:
- Test server starts without errors
- Verify FastMCP initialization with proper metadata
- Test lazy loading of WhisperTranscriber
- Verify environment variable loading
- Test error handling for missing dependencies
- Check logging is working correctly
